version: 2
job_name: batch-example
pipeline_options:
  streaming: False
  worker_harness_container_image: batch-example-job-image
  project: my-gcp-project
  worker_harness_container_image: streaming-dataflow-example-job-image
  experiments:
    - enable_stackdriver_agent_metrics
  region: europe-west1
  staging_location: gs://streaming-dataflow-example-bucket/staging
  num_workers: 2
  autoscaling_algorithm: NONE
  disk_size_gb: 50
  worker_disk_type: pd-ssd
  worker_machine_type: n1-highmem-2
  runner: DataflowRunner
  setup_file: setup.py
job_config:
  events:
    inputs:
      - type: file
        location: gs://batch-example-job/event-input/batch_track_ids.txt
        skip_klio_read: False
    outputs:
      - type: file
        location: gs://batch-example-job/event-output/batch_track_ids_output
        skip_klio_write: False
  data:
    inputs:
      - type: gcs
        location: gs://batch-example-job/my-input-bucket
        file_suffix: .ogg
        skip_klio_existence_check: False
    outputs:
      - type: gcs
        location: gs://batch-example-job/my-output-bucket
        file_suffix: .wav
        skip_klio_existence_check: False
